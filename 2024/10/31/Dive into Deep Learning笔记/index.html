
<!DOCTYPE html>
<html lang="zh">
    <head>
        <meta charset="utf-8" />
        <title>Dive into Deep Learning笔记一：预备知识 | lxy&#39;s blog!</title>
        <meta name="author" content="lxyaaada" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
        <link rel="icon" href="/images/favicon.png" />
        <script src="https://cdn.staticfile.org/vue/3.3.4/vue.global.prod.min.js"></script>
<link rel="stylesheet" href="https://cdn.staticfile.org/font-awesome/6.4.0/css/all.min.css" />
<link rel="stylesheet" href="/css/fonts.min.css" />
<script> const mixins = {}; </script>

<script src="https://polyfill.io/v3/polyfill.min.js?features=default"></script>


<script src="https://cdn.staticfile.org/highlight.js/11.8.0/highlight.min.js"></script>
<script src="https://cdn.staticfile.org/highlightjs-line-numbers.js/2.8.0/highlightjs-line-numbers.min.js"></script>
<link
    rel="stylesheet"
    href="https://cdn.staticfile.org/highlight.js/11.8.0/styles/github.min.css"
/>
<script src="/js/lib/highlight.js"></script>



<script src="/js/lib/preview.js"></script>









<link rel="stylesheet" href="/css/main.css" />

    <meta name="generator" content="Hexo 6.3.0"></head>
    <body>
        <div id="layout">
            <transition name="fade">
                <div id="loading" v-show="loading">
                    <div id="loading-circle">
                        <h2>LOADING</h2>
                        <p>加载过慢请开启缓存 浏览器默认开启</p>
                        <img src="/images/loading.gif" />
                    </div>
                </div>
            </transition>
            <div id="menu" :class="{ hidden: hiddenMenu, 'menu-color': menuColor}">
    <nav id="desktop-menu">
        <a class="title" href="/">
            <span>LXY&#39;S BLOG!</span>
        </a>
        
        <a href="/">
            <i class="fa-solid fa-house fa-fw"></i>
            <span>&ensp;Home</span>
        </a>
        
        <a href="/about">
            <i class="fa-solid fa-id-card fa-fw"></i>
            <span>&ensp;About</span>
        </a>
        
        <a href="/archives">
            <i class="fa-solid fa-box-archive fa-fw"></i>
            <span>&ensp;Archives</span>
        </a>
        
        <a href="/categories">
            <i class="fa-solid fa-bookmark fa-fw"></i>
            <span>&ensp;Categories</span>
        </a>
        
        <a href="/tags">
            <i class="fa-solid fa-tags fa-fw"></i>
            <span>&ensp;Tags</span>
        </a>
        
    </nav>
    <nav id="mobile-menu">
        <div class="title" @click="showMenuItems = !showMenuItems">
            <i class="fa-solid fa-bars fa-fw"></i>
            <span>&emsp;LXY&#39;S BLOG!</span>
        </div>
        <transition name="slide">
            <div class="items" v-show="showMenuItems">
                
                <a href="/">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-house fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Home</div>
                    </div>
                </a>
                
                <a href="/about">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-id-card fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">About</div>
                    </div>
                </a>
                
                <a href="/archives">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-box-archive fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Archives</div>
                    </div>
                </a>
                
                <a href="/categories">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-bookmark fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Categories</div>
                    </div>
                </a>
                
                <a href="/tags">
                    <div class="item">
                        <div style="min-width: 20px; max-width: 50px; width: 10%">
                            <i class="fa-solid fa-tags fa-fw"></i>
                        </div>
                        <div style="min-width: 100px; max-width: 150%; width: 20%">Tags</div>
                    </div>
                </a>
                
            </div>
        </transition>
    </nav>
</div>
<transition name="fade">
    <div id="menu-curtain" @click="showMenuItems = !showMenuItems" v-show="showMenuItems"></div>
</transition>

            <div id="main" :class="loading ? 'into-enter-from': 'into-enter-active'">
                <div class="article">
    <div>
        <h1>Dive into Deep Learning笔记一：预备知识</h1>
    </div>
    <div class="info">
        <span class="date">
            <span class="icon">
                <i class="fa-solid fa-calendar fa-fw"></i>
            </span>
            2024/10/31
        </span>
        
        <span class="category">
            <a href="/categories/%E6%B2%89%E6%B7%80/">
                <span class="icon">
                    <i class="fa-solid fa-bookmark fa-fw"></i>
                </span>
                沉淀
            </a>
        </span>
        
        
        <span class="tags">
            <span class="icon">
                <i class="fa-solid fa-tags fa-fw"></i>
            </span>
            
            <span class="tag">
                
                <a href="/tags/ML-DL/" style="color: #00bcd4">ML&amp;DL</a>
            </span>
            
        </span>
        
    </div>
    
    <div class="content" v-pre>
        <h1 id="Dive-into-Deep-Learning笔记"><a href="#Dive-into-Deep-Learning笔记" class="headerlink" title="Dive into Deep Learning笔记"></a>Dive into Deep Learning笔记</h1><span id="more"></span>

<h2 id="一、预备知识"><a href="#一、预备知识" class="headerlink" title="一、预备知识"></a>一、预备知识</h2><h3 id="1、数据操作"><a href="#1、数据操作" class="headerlink" title="1、数据操作"></a>1、数据操作</h3><p><strong>引入Pytorch库：</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>为张量中每个元素赋予确定值：</strong>如下</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>**符号：求幂运算。</p>
<p>对于任意具有相同形状的张量， 常见的标准算术运算符（<code>+</code>、<code>-</code>、<code>*</code>、<code>/</code>和<code>**</code>）都可以被升级为按元素运算。 我们可以在同一形状的任意两个张量上调用按元素操作。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>exp<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
<span class="token comment">#结果是tensor([2.7183e+00, 7.3891e+00, 5.4598e+01, 2.9810e+03]) 对应元素以e为底求幂</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><strong>张量连结（concatenate）：</strong>分别进行沿行（轴0）、沿列（轴1）的连结</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">12</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">2.0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">)</span><span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>结果为：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">7.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">8.</span><span class="token punctuation">,</span>  <span class="token number">9.</span><span class="token punctuation">,</span> <span class="token number">10.</span><span class="token punctuation">,</span> <span class="token number">11.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
 tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span> <span class="token number">0.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">5.</span><span class="token punctuation">,</span>  <span class="token number">6.</span><span class="token punctuation">,</span>  <span class="token number">7.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
         <span class="token punctuation">[</span> <span class="token number">8.</span><span class="token punctuation">,</span>  <span class="token number">9.</span><span class="token punctuation">,</span> <span class="token number">10.</span><span class="token punctuation">,</span> <span class="token number">11.</span><span class="token punctuation">,</span>  <span class="token number">4.</span><span class="token punctuation">,</span>  <span class="token number">3.</span><span class="token punctuation">,</span>  <span class="token number">2.</span><span class="token punctuation">,</span>  <span class="token number">1.</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>通过<em>逻辑运算符</em>构建二元张量：</strong>以<code>X == Y</code>为例： 对于每个位置，如果<code>X</code>和<code>Y</code>在该位置相等，则新张量中相应项的值为1（True）。 这意味着逻辑语句<code>X == Y</code>在该位置处为真，否则该位置为0（False）</p>
<p><strong>对两个矩阵广播</strong>：如a为[[0],[1],[2]]，b为[[0,1]],即a为3×1矩阵，b为1×2矩阵，进行a+b运算得到3×2矩阵。矩阵a复制列，矩阵b复制行，之后按元素相加。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
        <span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><strong>索引和切片：</strong>与任何Python数组一样：第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素。如可以用<code>[-1]</code>选择最后一个元素，可以用<code>[1:3]</code>选择第二个和第三个元素。如果我们想为多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值。 例如，<code>[0:2, :]</code>访问第1行和第2行，其中“:”代表沿轴1（列）的所有元素。 虽然我们讨论的是矩阵的索引，但这也适用于向量和超过2个维度的张量。</p>
<p><strong>原地操作节省内存：</strong>可以使用切片表示法将操作的结果分配给先前分配的数组，例如<code>Y[:] = &lt;expression&gt;</code></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">Z <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros_like<span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'id(Z):'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span>
Z<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">]</span> <span class="token operator">=</span> X <span class="token operator">+</span> Y
<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'id(Z):'</span><span class="token punctuation">,</span> <span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">140327634811696</span>
<span class="token builtin">id</span><span class="token punctuation">(</span>Z<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token number">140327634811696</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>如果在后续计算中没有重复使用<code>X</code>， 我们也可以使用<code>X[:] = X + Y</code>或<code>X += Y</code>来减少操作的内存开销。</p>
<p><strong>转换为其他Python对象：</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> X<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>A<span class="token punctuation">)</span>
<span class="token builtin">type</span><span class="token punctuation">(</span>A<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">type</span><span class="token punctuation">(</span>B<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(numpy.ndarray, torch.Tensor)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>要将大小为1的张量转换为Python标量，我们可以调用<code>item</code>函数或Python的内置函数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.5</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
a<span class="token punctuation">,</span> a<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">float</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">int</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token punctuation">(</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.5000</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="2、数据预处理"><a href="#2、数据预处理" class="headerlink" title="2、数据预处理"></a>2、数据预处理</h3><p>为了能用深度学习来解决现实世界的问题，我们经常从预处理原始数据开始， 而不是从那些准备好的张量格式数据开始。 在Python中常用的数据分析工具中，我们通常使用<code>pandas</code>软件包。 像庞大的Python生态系统中的许多其他扩展包一样，<code>pandas</code>可以与张量兼容。 </p>
<h4 id="（1）读取数据集"><a href="#（1）读取数据集" class="headerlink" title="（1）读取数据集"></a>（1）读取数据集</h4><p>**os.path.join()**：可以将多个传入路径组合为一个路径。实际上是将传入的几个字符串用系统的分隔符连接起来，组合成一个新的字符串，所以一般的用法是将第一个参数作为父目录，之后每一个参数即使下一级目录，从而组合成一个新的符合逻辑的路径。但如果传入路径中存在一个“绝对路径”格式的字符串，且这个字符串不是函数的第一个参数，那么其他在这个参数之前的所有参数都会被丢弃，余下的参数再进行组合。更准确地说，只有最后一个“绝对路径”及其之后的参数才会体现在返回结果中。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> os

os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
data_file <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span><span class="token string">'..'</span><span class="token punctuation">,</span> <span class="token string">'data'</span><span class="token punctuation">,</span> <span class="token string">'house_tiny.csv'</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>data_file<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NumRooms,Alley,Price\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 列名</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,Pave,127500\n'</span><span class="token punctuation">)</span>  <span class="token comment"># 每行表示一个数据样本</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'2,NA,106000\n'</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'4,NA,178100\n'</span><span class="token punctuation">)</span>
    f<span class="token punctuation">.</span>write<span class="token punctuation">(</span><span class="token string">'NA,NA,140000\n'</span><span class="token punctuation">)</span>
    
<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd

data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>data_file<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">   NumRooms Alley   Price
0       NaN  Pave  127500
1       2.0   NaN  106000
2       4.0   NaN  178100
3       NaN   NaN  140000<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="（2）处理缺失值"><a href="#（2）处理缺失值" class="headerlink" title="（2）处理缺失值"></a>（2）处理缺失值</h4><p>“NaN”项代表缺失值。 为了处理缺失的数据，典型的方法包括<em>插值法</em>和<em>删除法</em>， 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值。通过位置索引<code>iloc</code>，我们将<code>data</code>分成<code>inputs</code>和<code>outputs</code>， 其中前者为<code>data</code>的前两列，而后者为<code>data</code>的最后一列。 对于<code>inputs</code>中缺少的数值，我们用同一列的均值替换“NaN”项。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs<span class="token punctuation">,</span> outputs <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">:</span><span class="token number">2</span><span class="token punctuation">]</span><span class="token punctuation">,</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">]</span>
inputs <span class="token operator">=</span> inputs<span class="token punctuation">.</span>fillna<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment">#fillna():填充空值</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">   NumRooms Alley
0       3.0  Pave
1       2.0   NaN
2       4.0   NaN
3       3.0   NaN<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>对于<code>inputs</code>中的类别值或离散值，我们将“NaN”视为一个类别。 由于“巷子类型”（“Alley”）列只接受两种类型的类别值“Pave”和“NaN”， <code>pandas</code>可以自动将此列转换为列“Alley_Pave”和“Alley_nan”。 巷子类型为“Pave”的行会将“Alley_Pave”的值设置为1，“Alley_nan”的值设置为0。 缺少巷子类型的行会将“Alley_Pave”和“Alley_nan”分别设置为0和1。</p>
<p><strong>注：get_dummies函数：</strong>将离散特征转化为one hot编码，将每个离散取值看作状态。</p>
<p>dummy_na : bool, default False。增加一列表示空缺值，如果False就忽略空缺值。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">inputs <span class="token operator">=</span> pd<span class="token punctuation">.</span>get_dummies<span class="token punctuation">(</span>inputs<span class="token punctuation">,</span> dummy_na<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>inputs<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">   NumRooms  Alley_Pave  Alley_nan
0       3.0           1          0
1       2.0           0          1
2       4.0           0          1
3       3.0           0          1<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="（3）转换为张量格式"><a href="#（3）转换为张量格式" class="headerlink" title="（3）转换为张量格式"></a>（3）转换为张量格式</h4><p>现在<code>inputs</code>和<code>outputs</code>中的所有条目都是数值类型，它们可以转换为张量格式。 当数据采用张量格式后，可以通过在 <a target="_blank" rel="noopener" href="https://zh-v2.d2l.ai/chapter_preliminaries/ndarray.html#sec-ndarray">2.1节</a>中引入的那些张量函数来进一步操作。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

X <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>inputs<span class="token punctuation">.</span>to_numpy<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>to_numpy<span class="token punctuation">(</span>dtype<span class="token operator">=</span><span class="token builtin">float</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
X<span class="token punctuation">,</span> y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(tensor([[3., 1.],
         [2., 0.],
         [4., 0.],
         [3., 0.]], dtype&#x3D;torch.float64),
 tensor([127500., 106000., 178100., 140000.], dtype&#x3D;torch.float64))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>补充：dropna（）函数会删除含有缺失值的项。</p>
<h3 id="3、线性代数"><a href="#3、线性代数" class="headerlink" title="3、线性代数"></a>3、线性代数</h3><h4 id="（1）标量"><a href="#（1）标量" class="headerlink" title="（1）标量"></a>（1）标量</h4><p>torch.tensor()</p>
<h4 id="（2）向量"><a href="#（2）向量" class="headerlink" title="（2）向量"></a>（2）向量</h4><p>向量可以被视为标量值组成的列表。 这些标量值被称为向量的<em>元素</em>（element）或<em>分量</em>（component）。人们通过一维张量表示向量。一般来说，张量可以具有任意长度，取决于机器的内存限制。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">)</span>
x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([0, 1, 2, 3])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在代码中，我们通过张量的索引来访问任一元素。</p>
<h5 id="向量长度、维度和形状"><a href="#向量长度、维度和形状" class="headerlink" title="向量长度、维度和形状"></a>向量长度、维度和形状</h5><p>长度len(x)  shape表示张量沿每个轴的长度（维数）</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">torch.Size([4])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><em>向量</em>或<em>轴</em>的维度被用来表示<em>向量</em>或<em>轴</em>的长度，即向量或轴的元素数量。 然而，张量的维度用来表示张量具有的轴数。 在这个意义上，张量的某个轴的维数就是这个轴的长度</p>
<h4 id="（3）矩阵"><a href="#（3）矩阵" class="headerlink" title="（3）矩阵"></a>（3）矩阵</h4><p>A.T表示矩阵A的转置矩阵</p>
<p>对于对称矩阵B， B&#x3D;&#x3D;B.T得到如下结果</p>
<pre class="line-numbers language-none"><code class="language-none">tensor([[True, True, True],
        [True, True, True],
        [True, True, True]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h4 id="（4）张量-更高维度的矩阵"><a href="#（4）张量-更高维度的矩阵" class="headerlink" title="（4）张量 更高维度的矩阵"></a>（4）张量 更高维度的矩阵</h4><p>给定具有相同形状的任意两个张量，任何按元素二元运算的结果都将是相同形状的张量。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">20</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
B <span class="token operator">=</span> A<span class="token punctuation">.</span>clone<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 通过分配新内存，将A的一个副本分配给B</span>
A<span class="token punctuation">,</span> A <span class="token operator">+</span> B<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(tensor([[ 0.,  1.,  2.,  3.],
         [ 4.,  5.,  6.,  7.],
         [ 8.,  9., 10., 11.],
         [12., 13., 14., 15.],
         [16., 17., 18., 19.]]),
 tensor([[ 0.,  2.,  4.,  6.],
         [ 8., 10., 12., 14.],
         [16., 18., 20., 22.],
         [24., 26., 28., 30.],
         [32., 34., 36., 38.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>乘法运算也是一样 不改变张量形状</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">*</span> B<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([[  0.,   1.,   4.,   9.],
        [ 16.,  25.,  36.,  49.],
        [ 64.,  81., 100., 121.],
        [144., 169., 196., 225.],
        [256., 289., 324., 361.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>此外，将张量乘以或加上一个标量不会改变张量的形状，其中张量的每个元素都将与标量相加或相乘。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> <span class="token number">2</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">24</span><span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span>
a <span class="token operator">+</span> X<span class="token punctuation">,</span> a <span class="token operator">*</span> X <span class="token punctuation">,</span><span class="token punctuation">(</span>a <span class="token operator">*</span> X<span class="token punctuation">)</span><span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(tensor([[[ 2,  3,  4,  5],
          [ 6,  7,  8,  9],
          [10, 11, 12, 13]],
 
         [[14, 15, 16, 17],
          [18, 19, 20, 21],
          [22, 23, 24, 25]]]),
 tensor([[[ 0,  2,  4,  6],
          [ 8, 10, 12, 14],
          [16, 18, 20, 22]],
 
         [[24, 26, 28, 30],
          [32, 34, 36, 38],
          [40, 42, 44, 46]]]),
 torch.Size([2, 3, 4]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="（5）降维"><a href="#（5）降维" class="headerlink" title="（5）降维"></a>（5）降维</h4><p>A.sum用于张量所有元素求和，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。</p>
<p>可以指定张量哪一个轴通过求和来降低维度。以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指定<code>axis=0</code>。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A_sum_axis0 <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
A_sum_axis0<span class="token punctuation">,</span> A_sum_axis0<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(tensor([40., 45., 50., 55.]), torch.Size([4]))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>指定<code>axis=1</code>将通过汇总所有列的元素降维（轴1）。因此，输入轴1的维数在输出形状中消失。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A_sum_axis1 <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
A_sum_axis1<span class="token punctuation">,</span> A_sum_axis1<span class="token punctuation">.</span>shape<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(tensor([ 6., 22., 38., 54., 70.]), torch.Size([5]))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>也可以使用A.sum(axis &#x3D; [0,1])沿行列对矩阵求和，等价于对所有元素进行求和。</p>
<p>A.mean()用于求平均值，即将总和除以元素。同样，计算平均值的函数也可以沿指定轴降低张量的维度。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">,</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token operator">/</span> A<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
A<span class="token punctuation">.</span>mean<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token operator">/</span>A<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(tensor([ 8.,  9., 10., 11.]), tensor([ 8.,  9., 10., 11.]))
(tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]),
 tensor([ 1.5000,  5.5000,  9.5000, 13.5000, 17.5000]))<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p><strong>非降维求和：sum()函数中添加参数keepdims &#x3D; True来保持轴数不变。</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">sum_A <span class="token operator">=</span> A<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span>axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> keepdims<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
sum_A<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([[ 6.],
        [22.],
        [38.],
        [54.],
        [70.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>由于<code>sum_A</code>在对每行进行求和后仍保持两个轴，我们可以通过广播将<code>A</code>除以<code>sum_A</code> 相当于每列都除以sum_A。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A <span class="token operator">/</span> sum_A<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([[0.0000, 0.1667, 0.3333, 0.5000],
        [0.1818, 0.2273, 0.2727, 0.3182],
        [0.2105, 0.2368, 0.2632, 0.2895],
        [0.2222, 0.2407, 0.2593, 0.2778],
        [0.2286, 0.2429, 0.2571, 0.2714]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p><strong>cumsum()函数：</strong>沿某个轴计算元素累计总和，不会沿任何轴降低输入张量的维度。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>axis <span class="token operator">=</span> <span class="token number">0</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([[ 0.,  1.,  2.,  3.],
        [ 4.,  6.,  8., 10.],
        [12., 15., 18., 21.],
        [24., 28., 32., 36.],
        [40., 45., 50., 55.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="（6）点积-Dot-Product"><a href="#（6）点积-Dot-Product" class="headerlink" title="（6）点积 Dot Product"></a>（6）点积 Dot Product</h4><p><code>torch.dot(x,y)</code>计算x，y向量的点积（相同位置的按元素乘积的积）</p>
<p>也可以执行按元素乘法后进行求和表示向量的点积，即torch.sum(x * y)</p>
<h4 id="（7）矩阵-向量积-mv-matrix-vector"><a href="#（7）矩阵-向量积-mv-matrix-vector" class="headerlink" title="（7）矩阵-向量积 mv:matrix vector"></a>（7）矩阵-向量积 mv:matrix vector</h4><p>在代码中使用张量表示矩阵-向量积，我们使用<code>mv</code>函数。 当我们为矩阵<code>A</code>和向量<code>x</code>调用<code>torch.mv(A, x)</code>时，会执行矩阵-向量积。 注意，<code>A</code>的列维数（沿轴1的长度）必须与<code>x</code>的维数（其长度）相同。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">A<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> x<span class="token punctuation">.</span>shape<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>mv<span class="token punctuation">(</span>A<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">(torch.Size([5, 4]), torch.Size([4]), tensor([ 14.,  38.,  62.,  86., 110.]))<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="（8）矩阵-矩阵乘法-mm-：matrix-matrix"><a href="#（8）矩阵-矩阵乘法-mm-：matrix-matrix" class="headerlink" title="（8）矩阵-矩阵乘法 mm ：matrix matrix"></a>（8）矩阵-矩阵乘法 mm ：matrix matrix</h4><p>在下面的代码中，我们在<code>A</code>和<code>B</code>上执行矩阵乘法。 这里的<code>A</code>是一个5行4列的矩阵，<code>B</code>是一个4行3列的矩阵。 两者相乘后，我们得到了一个5行3列的矩阵。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">B <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>mm<span class="token punctuation">(</span>A<span class="token punctuation">,</span> B<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([[ 6.,  6.,  6.],
        [22., 22., 22.],
        [38., 38., 38.],
        [54., 54., 54.],
        [70., 70., 70.]])<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<h4 id="（9）范数"><a href="#（9）范数" class="headerlink" title="（9）范数"></a>（9）范数</h4><p>线性代数中最有用的一些运算符是<em>范数</em>（norm）。 非正式地说，向量的<em>范数</em>是表示一个向量有多大。 这里考虑的<em>大小</em>（size）概念不涉及维度，而是分量的大小。</p>
<p><img src="/2024/10/31/Dive%20into%20Deep%20Learning%E7%AC%94%E8%AE%B0/3" alt="3"></p>
<p><strong>欧几里得距离：L2范数</strong> 向量元素平方和的平方根</p>
<p>其中，在L2范数中常常省略下标2，也就是说‖x‖等同于‖x‖2。 在代码中，我们可以按如下方式计算向量的L2范数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">u <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3.0</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">4.0</span><span class="token punctuation">,</span> <span class="token number">12.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>u<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor(13.)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>L1范数：</strong>向量元素的绝对值之和。将绝对值函数和按元素求和形式组合。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span><span class="token builtin">abs</span><span class="token punctuation">(</span>u<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor(19.)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong><em>Frobenius范数</em>（Frobenius norm）</strong>是矩阵元素平方和的平方根：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">torch<span class="token punctuation">.</span>norm<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">4</span><span class="token punctuation">,</span> <span class="token number">9</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor(6.)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><strong>习题：考虑一个具有形状(2,3,4)的张量，在轴0、1、2上的求和输出是什么形状?</strong></p>
<p>答：分别是3×4，2×4，2×3的矩阵</p>
<h3 id="4、微积分"><a href="#4、微积分" class="headerlink" title="4、微积分"></a>4、微积分</h3><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">%</span>matplotlib inline <span class="token comment">#直接将图片画在jupyter notebook里面</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="（1）导数和微分"><a href="#（1）导数和微分" class="headerlink" title="（1）导数和微分"></a>（1）导数和微分</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> matplotlib_inline <span class="token keyword">import</span> backend_inline
<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> pyplot <span class="token keyword">as</span> plt
<span class="token keyword">import</span> d2l

<span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token number">3</span> <span class="token operator">*</span> x <span class="token operator">**</span> <span class="token number">2</span> <span class="token operator">-</span> <span class="token number">4</span> <span class="token operator">*</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>定义函数f(x)&#x3D;3x^2 - 4x</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">numerical_lim</span><span class="token punctuation">(</span>f<span class="token punctuation">,</span> x<span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">return</span> <span class="token punctuation">(</span>f<span class="token punctuation">(</span>x <span class="token operator">+</span> h<span class="token punctuation">)</span> <span class="token operator">-</span> f<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> h

h <span class="token operator">=</span> <span class="token number">0.1</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string-interpolation"><span class="token string">f'h=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>h<span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">&#125;</span></span><span class="token string">, numerical limit=</span><span class="token interpolation"><span class="token punctuation">&#123;</span>numerical_lim<span class="token punctuation">(</span>f<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> h<span class="token punctuation">)</span><span class="token punctuation">:</span><span class="token format-spec">.5f</span><span class="token punctuation">&#125;</span></span><span class="token string">'</span></span><span class="token punctuation">)</span>
    h <span class="token operator">*=</span> <span class="token number">0.1</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>numerical_lim函数定义导数值</p>
<p>为了对导数的这种解释进行可视化，我们将使用<code>matplotlib</code>， 这是一个Python中流行的绘图库。 要配置<code>matplotlib</code>生成图形的属性，我们需要定义几个函数。 在下面，<code>use_svg_display</code>函数指定<code>matplotlib</code>软件包输出svg图表以获得更清晰的图像。</p>
<p>注释<code>#@save</code>是一个特殊的标记，会将对应的函数、类或语句保存在<code>d2l</code>包中。 因此，以后无须重新定义就可以直接调用它们（例如，<code>d2l.use_svg_display()</code>）。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">use_svg_display</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""使用svg格式在Jupyter中显示绘图"""</span>
    backend_inline<span class="token punctuation">.</span>set_matplotlib_formats<span class="token punctuation">(</span><span class="token string">'svg'</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>定义<code>set_figsize</code>函数来设置图表大小。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">set_figsize</span><span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>  <span class="token comment">#@save</span>
    <span class="token triple-quoted-string string">"""设置matplotlib的图表大小"""</span>
    use_svg_display<span class="token punctuation">(</span><span class="token punctuation">)</span>
    plt<span class="token punctuation">.</span>rcParams<span class="token punctuation">[</span><span class="token string">'figure.figsize'</span><span class="token punctuation">]</span> <span class="token operator">=</span> figsize<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>下面的<code>set_axes</code>函数用于设置由<code>matplotlib</code>生成图表的轴的属性。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span>
<span class="token keyword">def</span> <span class="token function">set_axes</span><span class="token punctuation">(</span>axes<span class="token punctuation">,</span> xlabel<span class="token punctuation">,</span> ylabel<span class="token punctuation">,</span> xlim<span class="token punctuation">,</span> ylim<span class="token punctuation">,</span> xscale<span class="token punctuation">,</span> yscale<span class="token punctuation">,</span> legend<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""设置matplotlib的轴"""</span>
    axes<span class="token punctuation">.</span>set_xlabel<span class="token punctuation">(</span>xlabel<span class="token punctuation">)</span> <span class="token comment">#设置标签</span>
    axes<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span>ylabel<span class="token punctuation">)</span>
    axes<span class="token punctuation">.</span>set_xscale<span class="token punctuation">(</span>xscale<span class="token punctuation">)</span> <span class="token comment">#设置比例尺</span>
    axes<span class="token punctuation">.</span>set_yscale<span class="token punctuation">(</span>yscale<span class="token punctuation">)</span>
    axes<span class="token punctuation">.</span>set_xlim<span class="token punctuation">(</span>xlim<span class="token punctuation">)</span> <span class="token comment">#设置范围</span>
    axes<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span>ylim<span class="token punctuation">)</span>
    <span class="token keyword">if</span> legend<span class="token punctuation">:</span> <span class="token comment">#如果提供了 legend 参数，就会为图表添加图例。</span>
        axes<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>legend<span class="token punctuation">)</span>
    axes<span class="token punctuation">.</span>grid<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#启用网格线。</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>通过这三个用于图形配置的函数，定义一个<code>plot</code>函数来简洁地绘制多条曲线， 因为我们需要在整个书中可视化许多曲线。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment">#@save</span>
<span class="token keyword">def</span> <span class="token function">plot</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xlabel<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> ylabel<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xlim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span>
         ylim<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">,</span> xscale<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span> yscale<span class="token operator">=</span><span class="token string">'linear'</span><span class="token punctuation">,</span>
         fmts<span class="token operator">=</span><span class="token punctuation">(</span><span class="token string">'-'</span><span class="token punctuation">,</span> <span class="token string">'m--'</span><span class="token punctuation">,</span> <span class="token string">'g-.'</span><span class="token punctuation">,</span> <span class="token string">'r:'</span><span class="token punctuation">)</span><span class="token punctuation">,</span> figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">3.5</span><span class="token punctuation">,</span> <span class="token number">2.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span> axes<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""绘制数据点"""</span>
    <span class="token keyword">if</span> legend <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        legend <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>

    set_figsize<span class="token punctuation">(</span>figsize<span class="token punctuation">)</span>
    axes <span class="token operator">=</span> axes <span class="token keyword">if</span> axes <span class="token keyword">else</span> plt<span class="token punctuation">.</span>gca<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 如果X有一个轴，输出True</span>
    <span class="token keyword">def</span> <span class="token function">has_one_axis</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> <span class="token punctuation">(</span><span class="token builtin">hasattr</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token string">"ndim"</span><span class="token punctuation">)</span> <span class="token keyword">and</span> X<span class="token punctuation">.</span>ndim <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">or</span> <span class="token builtin">isinstance</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> <span class="token builtin">list</span><span class="token punctuation">)</span>
                <span class="token keyword">and</span> <span class="token keyword">not</span> <span class="token builtin">hasattr</span><span class="token punctuation">(</span>X<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">"__len__"</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token triple-quoted-string string">""" 如果 X 只有一个轴，则将其转为列表。如果 Y 为 None，则 X 和 Y 都为 X 的值。如果 Y 只有一个轴，则将其转为列表。如果 X 和 Y 的长度不一致，则将 X 扩展到 Y 的长度。"""</span>
    <span class="token keyword">if</span> has_one_axis<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> <span class="token punctuation">[</span>X<span class="token punctuation">]</span>
    <span class="token keyword">if</span> Y <span class="token keyword">is</span> <span class="token boolean">None</span><span class="token punctuation">:</span>
        X<span class="token punctuation">,</span> Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">,</span> X
    <span class="token keyword">elif</span> has_one_axis<span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        Y <span class="token operator">=</span> <span class="token punctuation">[</span>Y<span class="token punctuation">]</span>
    <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>X<span class="token punctuation">)</span> <span class="token operator">!=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span><span class="token punctuation">:</span>
        X <span class="token operator">=</span> X <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>Y<span class="token punctuation">)</span>
    axes<span class="token punctuation">.</span>cla<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment">#使用 axes.cla() 清除当前轴上的内容。</span>
    <span class="token keyword">for</span> x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fmt <span class="token keyword">in</span> <span class="token builtin">zip</span><span class="token punctuation">(</span>X<span class="token punctuation">,</span> Y<span class="token punctuation">,</span> fmts<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">if</span> <span class="token builtin">len</span><span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">:</span>
            axes<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> y<span class="token punctuation">,</span> fmt<span class="token punctuation">)</span>
        <span class="token keyword">else</span><span class="token punctuation">:</span>
            axes<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>y<span class="token punctuation">,</span> fmt<span class="token punctuation">)</span>
    set_axes<span class="token punctuation">(</span>axes<span class="token punctuation">,</span> xlabel<span class="token punctuation">,</span> ylabel<span class="token punctuation">,</span> xlim<span class="token punctuation">,</span> ylim<span class="token punctuation">,</span> xscale<span class="token punctuation">,</span> yscale<span class="token punctuation">,</span> legend<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>$$<br>绘 制 函 数 u &#x3D; f(x)及 其在x&#x3D;1处的切线y&#x3D;2x-3， 其中系数2是切线的斜率。<br>$$</p>
<p>函数和切线如下图所示</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x <span class="token operator">=</span> np<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">0.1</span><span class="token punctuation">)</span>
plot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> <span class="token punctuation">[</span>f<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span> <span class="token operator">*</span> x <span class="token operator">-</span> <span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token string">'x'</span><span class="token punctuation">,</span> <span class="token string">'f(x)'</span><span class="token punctuation">,</span> legend<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'f(x)'</span><span class="token punctuation">,</span> <span class="token string">'Tangent line (x=1)'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p><img src="/2024/10/31/Dive%20into%20Deep%20Learning%E7%AC%94%E8%AE%B0/1.png" alt="1"></p>
<h4 id="（2）偏导数与梯度"><a href="#（2）偏导数与梯度" class="headerlink" title="（2）偏导数与梯度"></a>（2）偏导数与梯度</h4><p>$$<br>偏导数：\frac{\partial y} {\partial x_{i}} &#x3D; \lim_{h\rightarrow0} \frac {f(x_{1},…,x_{i-1},x_i+h,x_{i+1},…,x_{n})-f(x_1,…,x_i,…,x_n)}{h}<br>$$</p>
<p>可以简单将其他变量看作为常数。</p>
<p>梯度：连结一个多元函数对其所有变量的偏导数，以得到该函数的<em>梯度</em>（gradient）向量<br>$$<br>设函数f:R^n\rightarrow R的输入是n维向量x &#x3D; [x_1,x_2,…,x_n]^T,且输出是一个标量。<br>$$</p>
<p>$$<br>函数f(x)相对于x的梯度是一个包含n个偏导数的向量：<br>\nabla_x f(x) &#x3D; [\frac{\partial f(x)}{\partial x_1},\frac{\partial f(x)}{\partial x_2},…,\frac{\partial f(x)}{\partial x_n}]^T<br>$$</p>
<p>$$<br>其中\nabla_xf(x)通常在没有歧义时被\nabla f(x)取代<br>$$</p>
<p><img src="/2024/10/31/Dive%20into%20Deep%20Learning%E7%AC%94%E8%AE%B0/2" alt="2"></p>
<h4 id="（3）链式法则"><a href="#（3）链式法则" class="headerlink" title="（3）链式法则"></a>（3）链式法则</h4><h3 id="5、自动微分"><a href="#5、自动微分" class="headerlink" title="5、自动微分"></a>5、自动微分</h3><p>深度学习框架通过自动计算导数，即<em>自动微分</em>（automatic differentiation）来加快求导。 实际中，根据设计好的模型，系统会构建一个<em>计算图</em>（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，<strong><em>反向传播</em>（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。</strong></p>
<h4 id="（1）作为一个演示例子，假设我们想对函数"><a href="#（1）作为一个演示例子，假设我们想对函数" class="headerlink" title="（1）作为一个演示例子，假设我们想对函数"></a>（1）作为一个演示例子，假设我们想对函数</h4><p>$$<br>y &#x3D; 2x^Tx<br>$$</p>
<p>关于列向量x求导。 首先，我们创建变量<code>x</code>并为其分配一个初始值。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

x <span class="token operator">=</span> torch<span class="token punctuation">.</span>arange<span class="token punctuation">(</span><span class="token number">4.0</span><span class="token punctuation">)</span>
x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>

<p>在我们计算y关于x的梯度之前，需要一个地方来存储梯度。 重要的是，我们不会在每次对一个参数求导时都分配新的内存。 因为我们经常会成千上万次地更新相同的参数，每次都分配新的内存可能很快就会将内存耗尽。 注意，<strong>一个标量函数关于向量x的梯度是向量，并且与x具有相同的形状。</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>requires_grad_<span class="token punctuation">(</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment"># 等价于x=torch.arange(4.0,requires_grad=True)</span>
x<span class="token punctuation">.</span>grad  <span class="token comment"># 默认值是None</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<p>现在计算y</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">y <span class="token operator">=</span> <span class="token number">2</span> <span class="token operator">*</span> torch<span class="token punctuation">.</span>dot<span class="token punctuation">(</span>x<span class="token punctuation">,</span> x<span class="token punctuation">)</span>
y<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor(28., grad_fn&#x3D;&lt;MulBackward0&gt;)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p><code>x</code>是一个长度为4的向量，计算<code>x</code>和<code>x</code>的点积，得到了我们赋值给<code>y</code>的标量输出。 接下来，通过调用<strong>反向传播函数</strong>来自动计算<code>y</code>关于<code>x</code>每个分量的梯度，并打印这些梯度。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([ 0.,  4.,  8., 12.])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>$$<br>y &#x3D; 2x^Tx的梯度应该为y &#x3D; 4x，进行检验<br>$$</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad <span class="token operator">==</span> <span class="token number">4</span><span class="token operator">*</span>x<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([True, True, True, True])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在去计算x的另一个函数：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值</span>
x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
y<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([1., 1., 1., 1.])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="（2）非标量变量反向传播"><a href="#（2）非标量变量反向传播" class="headerlink" title="（2）非标量变量反向传播"></a>（2）非标量变量反向传播</h4><p>当<code>y</code>不是标量时，向量<code>y</code>关于向量<code>x</code>的导数的最自然解释是一个矩阵。 对于高阶和高维的<code>y</code>和<code>x</code>，求导的结果可以是一个高阶张量。</p>
<p>然而，虽然这些更奇特的对象确实出现在高级机器学习中（包括深度学习中）， 但当调用向量的反向计算时，我们通常会试图计算一批训练样本中每个组成部分的损失函数的导数。 这里，我们的目的不是计算微分矩阵，而是单独计算批量中每个样本的偏导数之和。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># 对非标量调用backward需要传入一个gradient参数，该参数指定微分函数关于self的梯度。</span>
<span class="token comment"># 本例只想求偏导数的和，所以传递一个1的梯度是合适的</span>
x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x <span class="token operator">*</span> x
<span class="token comment"># 等价于y.backward(torch.ones(len(x)))</span>
y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([0., 2., 4., 6.])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="（3）分离计算"><a href="#（3）分离计算" class="headerlink" title="（3）分离计算"></a>（3）分离计算</h4><p>有时，我们希望将某些计算移动到记录的计算图之外。 例如，假设<code>y</code>是作为<code>x</code>的函数计算的，而<code>z</code>则是作为<code>y</code>和<code>x</code>的函数计算的。 想象一下，我们想计算<code>z</code>关于<code>x</code>的梯度，但由于某种原因，希望将<code>y</code>视为一个常数， 并且只考虑到<code>x</code>在<code>y</code>被计算后发挥的作用。</p>
<p>这里可以分离<code>y</code>来返回一个新变量<code>u</code>，该变量与<code>y</code>具有相同的值， 但丢弃计算图中如何计算<code>y</code>的任何信息。 换句话说，梯度不会向后流经<code>u</code>到<code>x</code>。 因此，下面的反向传播函数计算<code>z=u*x</code>关于<code>x</code>的偏导数，同时将<code>u</code>作为常数处理， 而不是<code>z=x*x*x</code>关于<code>x</code>的偏导数。</p>
<p><code>detach()</code> 方法用于返回一个新的 Tensor，这个 Tensor 和原来的 Tensor 共享相同的内存空间，但是不会被计算图所追踪，也就是说它不会参与反向传播，不会影响到原有的计算图。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> x <span class="token operator">*</span> x
u <span class="token operator">=</span> y<span class="token punctuation">.</span>detach<span class="token punctuation">(</span><span class="token punctuation">)</span>
z <span class="token operator">=</span> u <span class="token operator">*</span> x

z<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad <span class="token operator">==</span> u<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([True, True, True, True])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>由于记录了<code>y</code>的计算结果，我们可以随后在<code>y</code>上调用反向传播， 得到<code>y=x*x</code>关于的<code>x</code>的导数，即<code>2*x</code>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">x<span class="token punctuation">.</span>grad<span class="token punctuation">.</span>zero_<span class="token punctuation">(</span><span class="token punctuation">)</span>
y<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
x<span class="token punctuation">.</span>grad <span class="token operator">==</span> <span class="token number">2</span> <span class="token operator">*</span> x<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([True, True, True, True])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="（4）Python控制流的梯度计算"><a href="#（4）Python控制流的梯度计算" class="headerlink" title="（4）Python控制流的梯度计算"></a>（4）Python控制流的梯度计算</h4><p>使用自动微分的一个好处是： 即使构建函数的计算图需要通过Python控制流（例如，条件、循环或任意函数调用），我们仍然可以计算得到的变量的梯度。 在下面的代码中，<code>while</code>循环的迭代次数和<code>if</code>语句的结果都取决于输入<code>a</code>的值。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">f</span><span class="token punctuation">(</span>a<span class="token punctuation">)</span><span class="token punctuation">:</span>
    b <span class="token operator">=</span> a <span class="token operator">*</span> <span class="token number">2</span>
    <span class="token keyword">while</span> b<span class="token punctuation">.</span>norm<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&lt;</span> <span class="token number">1000</span><span class="token punctuation">:</span>
        b <span class="token operator">=</span> b <span class="token operator">*</span> <span class="token number">2</span>
    <span class="token keyword">if</span> b<span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> <span class="token number">0</span><span class="token punctuation">:</span>
        c <span class="token operator">=</span> b
    <span class="token keyword">else</span><span class="token punctuation">:</span>
        c <span class="token operator">=</span> <span class="token number">100</span> <span class="token operator">*</span> b
    <span class="token keyword">return</span> c<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>

<p>接下来计算梯度</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a <span class="token operator">=</span> torch<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> requires_grad<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
d <span class="token operator">=</span> f<span class="token punctuation">(</span>a<span class="token punctuation">)</span>
d<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>我们现在可以分析上面定义的<code>f</code>函数。 请注意，它在其输入<code>a</code>中是分段线性的。 换言之，对于任何<code>a</code>，存在某个常量标量<code>k</code>，使得<code>f(a)=k*a</code>，其中<code>k</code>的值取决于输入<code>a</code>，因此可以用<code>d/a</code>验证梯度是否正确。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">a<span class="token punctuation">.</span>grad <span class="token operator">==</span> d <span class="token operator">/</span> a<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor(True)<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h4 id="（5）小结"><a href="#（5）小结" class="headerlink" title="（5）小结"></a>（5）小结</h4><ul>
<li>深度学习框架可以自动计算导数：我们首先将梯度附加到想要对其计算偏导数的变量上，然后记录目标值的计算，执行它的反向传播函数，并访问得到的梯度。</li>
</ul>
<h3 id="6、概率"><a href="#6、概率" class="headerlink" title="6、概率"></a>6、概率</h3><h4 id="（1）基本概率论"><a href="#（1）基本概率论" class="headerlink" title="（1）基本概率论"></a>（1）基本概率论</h4><p>首先，我们导入必要的软件包。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token operator">%</span>matplotlib inline
<span class="token keyword">import</span> torch
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>distributions <span class="token keyword">import</span> multinomial<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<p>在统计学中，我们把从概率分布中抽取样本的过程称为<em>抽样</em>（sampling）。 笼统来说，可以把<em>分布</em>（distribution）看作对事件的概率分配， 稍后我们将给出的更正式定义。 将概率分配给一些离散选择的分布称为<em>多项分布</em>（multinomial distribution）。</p>
<p>为了抽取一个样本，即掷骰子，我们只需传入一个概率向量。 输出是另一个相同长度的向量：它在索引i处的值是采样结果中i出现的次数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">fair_probs <span class="token operator">=</span> torch<span class="token punctuation">.</span>ones<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">6</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">6</span>
multinomial<span class="token punctuation">.</span>Multinomial<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> fair_probs<span class="token punctuation">)</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([0., 1., 0., 0., 0., 0.])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>在估计一个骰子的公平性时，我们希望从同一分布中生成多个样本。 如果用Python的for循环来完成这个任务，速度会慢得惊人。 因此我们使用深度学习框架的函数同时抽取多个样本，得到我们想要的任意形状的独立样本数组。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">multinomial<span class="token punctuation">.</span>Multinomial<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> fair_probs<span class="token punctuation">)</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([0., 2., 2., 0., 2., 4.])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<p>现在我们知道如何对骰子进行采样，我们可以模拟1000次投掷。 然后，我们可以统计1000次投掷后，每个数字被投中了多少次。 具体来说，我们计算相对频率，以作为真实概率的估计。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">counts <span class="token operator">=</span> multinomial<span class="token punctuation">.</span>Multinomial<span class="token punctuation">(</span><span class="token number">1000</span><span class="token punctuation">,</span> fair_probs<span class="token punctuation">)</span><span class="token punctuation">.</span>sample<span class="token punctuation">(</span><span class="token punctuation">)</span>
counts<span class="token operator">/</span><span class="token number">1000</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>

<pre class="line-numbers language-none"><code class="language-none">tensor([0.1640, 0.1620, 0.1820, 0.1640, 0.1500, 0.1780])<span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>

<h3 id="7、查阅文档"><a href="#7、查阅文档" class="headerlink" title="7、查阅文档"></a>7、查阅文档</h3><h4 id="（1）查找模块中所有函数和类"><a href="#（1）查找模块中所有函数和类" class="headerlink" title="（1）查找模块中所有函数和类"></a>（1）查找模块中所有函数和类</h4><pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> torch

<span class="token keyword">print</span><span class="token punctuation">(</span><span class="token builtin">dir</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>distributions<span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>

<h4 id="（2）查找特定函数、类的用法"><a href="#（2）查找特定函数、类的用法" class="headerlink" title="（2）查找特定函数、类的用法"></a>（2）查找特定函数、类的用法</h4><p>有关如何使用给定函数或类的更具体说明，可以调用<code>help</code>函数。 例如，我们来查看张量<code>ones</code>函数的用法。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token builtin">help</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>ones<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>


    </div>
    
    
    
    
    
    
    
</div>

                <footer id="footer">
    <div id="footer-wrap">
        <div>
            &copy;
            2022 - 2024 lxy&#39;s blog!
            <span id="footer-icon">
                <i class="fa-solid fa-font-awesome fa-fw"></i>
            </span>
            &commat;lxyaaada
        </div>
        <div>
            Based on the <a target="_blank" rel="noopener" href="https://hexo.io">Hexo Engine</a> &amp;
            <a target="_blank" rel="noopener" href="https://github.com/theme-particlex/hexo-theme-particlex">ParticleX Theme</a>
        </div>
        
    </div>
</footer>

            </div>
            
            <transition name="fade">
                <div id="preview" ref="preview" v-show="previewShow">
                    <img id="preview-content" ref="previewContent" />
                </div>
            </transition>
            
        </div>
        <script src="/js/main.js"></script>
        
        




        
    <script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"model":{"jsonPath":"/live2dw/assets/izumi.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":false},"log":false,"pluginJsPath":"lib/","pluginModelPath":"assets/","pluginRootPath":"live2dw/","tagMode":false});</script></body>
</html>
